{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear classifiers\n",
    "Try with nonlinear classifiers, can you do better than the baseline models from above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib; import cours_proj4_funcs; \n",
    "importlib.reload(cours_proj4_funcs)\n",
    "from cours_proj4_funcs import f_read_npzF, f_addIdxFeat, f_fileApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "X_tr_ini, y_tr_ini, X_data_tr, fnames_tr, y_cat_tr = f_read_npzF(os.path.join('data', 'data_train.npz'))\n",
    "X_tr_ini1 = f_addIdxFeat(X_tr_ini)\n",
    "\n",
    "X_va_ini, y_va_ini, X_data_va, fnames_va, y_cat_va = f_read_npzF(os.path.join('data', 'data_valid.npz'))\n",
    "X_va_ini1 = f_addIdxFeat(X_va_ini)\n",
    "\n",
    "X_te_ini, y_te_ini, X_data_te, fnames_te, y_cat_te = f_read_npzF(os.path.join('data', 'data_test.npz'))\n",
    "X_te_ini1 = f_addIdxFeat(X_te_ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Try with a random Forest, does increasing the number of trees help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>test score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>200</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.0</td>\n",
       "      <td>200</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  n_estimators  test score\n",
       "14        5.0           200        0.94\n",
       "10        5.0           100        0.92\n",
       "15        NaN           200        0.92\n",
       "11        NaN           100        0.90\n",
       "6         5.0            10        0.86\n",
       "7         NaN            10        0.80\n",
       "9         3.0           100        0.78\n",
       "13        3.0           200        0.78\n",
       "5         3.0            10        0.74\n",
       "3         NaN             1        0.64\n",
       "1         3.0             1        0.62\n",
       "2         5.0             1        0.62\n",
       "12        1.0           200        0.62\n",
       "8         1.0           100        0.60\n",
       "4         1.0            10        0.52\n",
       "0         1.0             1        0.42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "gs_results_rf = []\n",
    "\n",
    "for n_est in [1, 10, 100, 200]: #g in [0.1, 100, 1000, 'auto']: #[0.1, 1, 10]\n",
    "    for m_depth in [1, 3, 5, None]:\n",
    "        #print (g)\n",
    "        rfc = RandomForestClassifier(n_estimators=n_est, max_depth=m_depth, random_state=0)\n",
    "        # Fit estimator\n",
    "        rfc.fit(X_tr_ini, y_tr_ini);\n",
    "        \n",
    "        gs_results_rf.append({ \"n_estimators\": n_est\n",
    "                               ,\"max_depth\" : m_depth\n",
    "                               ,\"test score\": rfc.score(X_te_ini, y_te_ini) })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "gs_results_rf = pd.DataFrame(gs_results_rf)\n",
    "gs_results_rf.sort_values(\"test score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we see above, for **Random forest** with `tree=3`, the best test accuracy is `0.78`. We can also also say that increasing the number of trees, i.e to `5`, we get better score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest accuracy to append into the file \n",
    "f_fileApp('data/results09.csv',3,\"random forest\", 0.78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Try with SVM Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC test accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Create SVM with linear kernel\n",
    "linear_svc = LinearSVC()\n",
    "\n",
    "# Fit estimator\n",
    "linear_svc.fit(X_tr_ini, y_tr_ini);\n",
    "\n",
    "test_acc_lsvc = linear_svc.score(X_te_ini, y_te_ini)\n",
    "\n",
    "print(\"Linear SVC test accuracy: {}\".format(test_acc_lsvc))\n",
    "f_fileApp('data/results09.csv',4,\"svm linear\", test_acc_lsvc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### does the SVM RBF kernel perform better than the linear one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "gs_results_svm = []\n",
    "\n",
    "for c in [0.1, 1, 3, 5, 10]:\n",
    "    for g in [0.1, 10, 100, 1000, 'auto']:\n",
    "        #print (g)\n",
    "        rbf_svc_cg = SVC(kernel='rbf', C=c, gamma=g)\n",
    "        # Fit estimator\n",
    "        rbf_svc_cg.fit(X_tr_ini, y_tr_ini);\n",
    "        \n",
    "        gs_results_svm.append({ \"C\": c\n",
    "                               ,\"gamma\" : g\n",
    "                               ,\"test score\": rbf_svc_cg.score(X_te_ini, y_te_ini) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>test score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C gamma  test score\n",
       "14   3.0  auto        0.96\n",
       "9    1.0  auto        0.96\n",
       "24  10.0  auto        0.94\n",
       "19   5.0  auto        0.94\n",
       "4    0.1  auto        0.56"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert results to DataFrame\n",
    "gs_results_svm = pd.DataFrame(gs_results_svm)\n",
    "gs_results_svm.sort_values(\"test score\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the parameters `C=3` and `gamma='auto'`, we get a score of `0.96`. So that with the parameters mentioned, it seems to be better than the linear one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest accuracy to append into the file \n",
    "f_fileApp('data/results09.csv',5,\"vm rbf\", 0.96)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
