{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01 Course project - Welcome\n",
    "---\n",
    "In this final course project, you will have the chance to demonstrate what you have learned during the last courses in a concrete machine learning project: **building an image classifier**.\n",
    "\n",
    "For this project, you will work on the **Swissroads** data set which contains several hundreds images of vehicles found in the EPFL - Lausanne area including **cars, trucks, vans, bikes, motorcycles and others**.\n",
    "\n",
    "The goal of this project is to **test the different classifiers** and techniques from the course using high-level features extracted with a **pretrained** convolutional neural network from **TensorFlow Hub** and compare the results with your own **ConvNet** implementation trained from the raw image pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Image classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction \n",
    "\n",
    "In this first part of the project, start by extracting a set of **high-level features** for each image in the data set. To achieve this, you can use ex. the <a href=\"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1\">Inception v3</a> or <a href=\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\">MobileNet v2</a> ConvNets which respectively extract 2048 and 1280 **high-level features**.\n",
    "\n",
    "Suggestion: consider storing the extracted high-level features, e.g. in npz files, for quickly reloading them into each of the following notebooks.\n",
    "\n",
    "**Note**: All your models should be **trained** on the training set, and the fine tuning of your hyperparameters should be **validated** on the validation set. The final test set should only be used for the final comparison to **test** the accuracies of your models on a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create image generator\n",
    "train_generator = ImageDataGenerator(rescale = 1/255\n",
    "                                    #,horizontal_flip = True\n",
    "                                    #,rotation_range = 5\n",
    "                                    ,validation_split = None) #0.2 )\n",
    "\n",
    "valid_generator = ImageDataGenerator(rescale = 1/255 )\n",
    "test_generator = ImageDataGenerator(rescale = 1/255 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 6 classes.\n",
      "Found 139 images belonging to 6 classes.\n",
      "Found 50 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "trainset = train_generator.flow_from_directory( os.path.join(\"data/swissroads\", 'train')\n",
    "                                               ,batch_size = 32\n",
    "                                               ,target_size = (224, 224)\n",
    "                                               ,shuffle = False #as not splitting\n",
    "                                               )#,subset = 'training' )\n",
    "\n",
    "validset = valid_generator.flow_from_directory( os.path.join('data/swissroads', 'valid')\n",
    "                                               ,batch_size = 32\n",
    "                                               ,target_size = (224, 224)\n",
    "                                               ,shuffle = False\n",
    "                                               )#,subset = 'validation' )\n",
    "\n",
    "testset = test_generator.flow_from_directory( os.path.join('data/swissroads', 'test')\n",
    "                                             ,batch_size = 32\n",
    "                                             ,target_size = (224, 224)\n",
    "                                             ,shuffle = False\n",
    "                                             )#,subset = 'validation' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#function piling all director batches and return a whole one\n",
    "def f_get_wholeImgBatch(p_directIter, p_DI_sizeBatch=32):\n",
    "    img_batches = None\n",
    "    lbl_batches = None\n",
    "    \n",
    "    while True:\n",
    "        batch_imgs, batch_labels = p_directIter.next()\n",
    "\n",
    "        if img_batches is None:\n",
    "            img_batches = batch_imgs\n",
    "            lbl_batches = batch_labels\n",
    "        else:\n",
    "            img_batches= np.concatenate((img_batches, batch_imgs), axis=0)\n",
    "            lbl_batches= np.concatenate((lbl_batches, batch_labels), axis=0)\n",
    "            \n",
    "\n",
    "        if batch_imgs.shape[0] < p_DI_sizeBatch or img_batches is None:\n",
    "            break;\n",
    "    \n",
    "    if img_batches is not None and img_batches.shape[0]<len(p_directIter.filenames):\n",
    "        #gets into 2th nested function\n",
    "        return f_get_wholeImgBatch(p_directIter, p_DI_sizeBatch)\n",
    "    \n",
    "    return img_batches, lbl_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (280, 224, 224, 3) float32 (280,) int32\n",
      "Valid (139, 224, 224, 3) float32 (139,) int32\n",
      "Test (50, 224, 224, 3) float32 (50,) int32\n"
     ]
    }
   ],
   "source": [
    "# train data set\n",
    "img_batches_tr, lbl_batches_tr = f_get_wholeImgBatch(trainset, 32)\n",
    "targ_tr = np.matmul(lbl_batches_tr, np.array(list(trainset.class_indices.values())) ).astype(np.int32)\n",
    "\n",
    "# validation data set\n",
    "img_batches_va, lbl_batches_va = f_get_wholeImgBatch(validset, 32)\n",
    "targ_va = np.matmul(lbl_batches_va, np.array(list(validset.class_indices.values())) ).astype(np.int32)\n",
    "\n",
    "# test data set\n",
    "img_batches_te, lbl_batches_te = f_get_wholeImgBatch(testset, 32)\n",
    "targ_te = np.matmul(lbl_batches_te, np.array(list(testset.class_indices.values())) ).astype(np.int32)\n",
    "\n",
    "print(\"Train\", img_batches_tr.shape, img_batches_tr.dtype, targ_tr.shape, targ_tr.dtype)\n",
    "print(\"Valid\", img_batches_va.shape, img_batches_va.dtype, targ_va.shape, targ_va.dtype)\n",
    "print(\"Test\", img_batches_te.shape, img_batches_te.dtype, targ_te.shape, targ_te.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_create_graph(p_mod_url='https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2'):\n",
    "    # Create graph\n",
    "    img_graph = tf.Graph()\n",
    "\n",
    "    with img_graph.as_default():\n",
    "        # Download module\n",
    "        module_url = p_mod_url\n",
    "        feature_extractor = hub.Module(module_url)\n",
    "\n",
    "        # Create input placeholder\n",
    "        input_imgs = tf.placeholder(dtype=tf.float32, shape=[None, 224, 224, 3])\n",
    "\n",
    "        # A node with the features\n",
    "        imgs_features = feature_extractor(input_imgs)\n",
    "\n",
    "        # Collect initializers\n",
    "        init_op = tf.group( [tf.global_variables_initializer()\n",
    "                            ,tf.tables_initializer() ] )\n",
    "\n",
    "    img_graph.finalize() # Good practice: make the graph \"read-only\"\n",
    "    \n",
    "    return img_graph, input_imgs, imgs_features, init_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session\n",
    "def f_create_sess(p_img_graph, p_input_imgs, p_imgs_features, p_init_op, p_img_batches):\n",
    "    sess = tf.Session(graph=p_img_graph)\n",
    "\n",
    "    # Initialize it\n",
    "    sess.run(p_init_op)\n",
    "\n",
    "    # Extract features\n",
    "    features = sess.run(p_imgs_features, feed_dict={p_input_imgs: p_img_batches})\n",
    "    #features.shape\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to save data as a npz file \n",
    "def f_save_npzF(p_pathFile, p_feat, p_targ, p_data, p_fnames=None, p_categ_names=None):\n",
    "    np.savez(p_pathFile, features=p_feat, category=p_targ, data=p_data, filenames=p_fnames, categorynames=p_categ_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_dict2array1(p_dict):\n",
    "    cat_names=[]\n",
    "    for k, v in trainset.class_indices.items():\n",
    "        cat_names.append(str(v)+\":\"+k)\n",
    "    \n",
    "    return cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var features  (280, 1280)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "##** treating Train data set: img_batches_tr, lbl_batches_tr\n",
    "\n",
    "img_graph, input_imgs, imgs_features, init_op = f_create_graph()\n",
    "\n",
    "feat = f_create_sess(img_graph, input_imgs, imgs_features, init_op, img_batches_tr)\n",
    "print(\"var features \",feat.shape)\n",
    "\n",
    "f_save_npzF(\"data/data_train.npz\", feat, targ_tr, img_batches_tr, np.array(trainset.filenames), f_dict2array1(trainset.class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var features  (139, 1280)\n"
     ]
    }
   ],
   "source": [
    "#Validation: img_batches_va, lbl_batches_va\n",
    "\n",
    "img_graph, input_imgs, imgs_features, init_op = f_create_graph()\n",
    "\n",
    "feat = f_create_sess(img_graph, input_imgs, imgs_features, init_op, img_batches_va)\n",
    "print(\"var features \",feat.shape)\n",
    "\n",
    "f_save_npzF(\"data/data_valid.npz\", feat, targ_va, img_batches_va, np.array(validset.filenames), f_dict2array1(validset.class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var features  (50, 1280)\n"
     ]
    }
   ],
   "source": [
    "#Test: img_batches_te, lbl_batches_te\n",
    "\n",
    "img_graph, input_imgs, imgs_features, init_op = f_create_graph()\n",
    "\n",
    "feat = f_create_sess(img_graph, input_imgs, imgs_features, init_op, img_batches_te)\n",
    "print(\"var features \",feat.shape)\n",
    "\n",
    "f_save_npzF(\"data/data_test.npz\", feat, targ_te, img_batches_tr, np.array(testset.filenames), f_dict2array1(testset.class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fRes = open(\"data/results09.csv\",\"w+\")\n",
    "#fRes.write(\"This is line %d\\n\" % (i+1))\n",
    "fRes.write('idx,model,test_accuracy'+'\\r\\n') \n",
    "fRes.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
